{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-21 12:31:52.758655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from keras import models, layers, optimizers, initializers, Input\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['ResponseID', 'ExtendedSessionID', 'UserID', 'AttributeLevel','ScenarioTypeStrict']] = df[['ResponseID', 'ExtendedSessionID', 'UserID', 'AttributeLevel','ScenarioTypeStrict']].astype(str)\n",
    "df[[\"PedPed\", \"Barrier\", \"CrossingSignal\", \"NumberOfCharacters\", \"DiffNumberOFCharacters\", \"Man\", \"Woman\", \"Pregnant\", \"Stroller\", \"OldMan\", \"OldWoman\", \"Boy\", \"Girl\", \"Homeless\", \"LargeWoman\", \"LargeMan\", \"Criminal\", \"MaleExecutive\", \"FemaleExecutive\", \"FemaleAthlete\", \"MaleAthlete\", \"FemaleDoctor\", \"MaleDoctor\", \"Dog\", \"Cat\", \"Saved\"]] = df[[\"PedPed\", \"Barrier\", \"CrossingSignal\", \"NumberOfCharacters\", \"DiffNumberOFCharacters\", \"Man\", \"Woman\", \"Pregnant\", \"Stroller\", \"OldMan\", \"OldWoman\", \"Boy\", \"Girl\", \"Homeless\", \"LargeWoman\", \"LargeMan\", \"Criminal\", \"MaleExecutive\", \"FemaleExecutive\", \"FemaleAthlete\", \"MaleAthlete\", \"FemaleDoctor\", \"MaleDoctor\", \"Dog\", \"Cat\", \"Saved\"]].astype(float).round().astype('int8')\n",
    "df[[\"Finance_access\", \"ICT\", \"Industry_activity\", \"Overall_index\", \"Research_and_development\", \"Skills\", \"Total\", \"Males\", \"Females\", \"Passengers\", \"Pedestrians\"]] = df[[\"Finance_access\", \"ICT\", \"Industry_activity\", \"Overall_index\", \"Research_and_development\", \"Skills\", \"Total\", \"Males\", \"Females\", \"Passengers\", \"Pedestrians\"]].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResponseID                   object\n",
       "ExtendedSessionID            object\n",
       "UserID                       object\n",
       "PedPed                         int8\n",
       "Barrier                        int8\n",
       "CrossingSignal                 int8\n",
       "AttributeLevel               object\n",
       "ScenarioTypeStrict           object\n",
       "NumberOfCharacters             int8\n",
       "DiffNumberOFCharacters         int8\n",
       "Saved                          int8\n",
       "Country                      object\n",
       "Man                            int8\n",
       "Woman                          int8\n",
       "Pregnant                       int8\n",
       "Stroller                       int8\n",
       "OldMan                         int8\n",
       "OldWoman                       int8\n",
       "Boy                            int8\n",
       "Girl                           int8\n",
       "Homeless                       int8\n",
       "LargeWoman                     int8\n",
       "LargeMan                       int8\n",
       "Criminal                       int8\n",
       "MaleExecutive                  int8\n",
       "FemaleExecutive                int8\n",
       "FemaleAthlete                  int8\n",
       "MaleAthlete                    int8\n",
       "FemaleDoctor                   int8\n",
       "MaleDoctor                     int8\n",
       "Dog                            int8\n",
       "Cat                            int8\n",
       "Finance_access              float32\n",
       "ICT                         float32\n",
       "Industry_activity           float32\n",
       "Overall_index               float32\n",
       "Research_and_development    float32\n",
       "Skills                      float32\n",
       "Total                       float32\n",
       "Males                       float32\n",
       "Females                     float32\n",
       "Passengers                  float32\n",
       "Pedestrians                 float32\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>NumberOfCharacters</th>\n",
       "      <th>DiffNumberOFCharacters</th>\n",
       "      <th>Saved</th>\n",
       "      <th>Country</th>\n",
       "      <th>Man</th>\n",
       "      <th>Woman</th>\n",
       "      <th>Pregnant</th>\n",
       "      <th>Stroller</th>\n",
       "      <th>OldMan</th>\n",
       "      <th>OldWoman</th>\n",
       "      <th>Boy</th>\n",
       "      <th>Girl</th>\n",
       "      <th>Homeless</th>\n",
       "      <th>LargeWoman</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Finance_access</th>\n",
       "      <th>ICT</th>\n",
       "      <th>Industry_activity</th>\n",
       "      <th>Overall_index</th>\n",
       "      <th>Research_and_development</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Total</th>\n",
       "      <th>Males</th>\n",
       "      <th>Females</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Pedestrians</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2223Xu54ufgjcyMR3</td>\n",
       "      <td>1425316635_327833569077076.0</td>\n",
       "      <td>327833569077076.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Old</td>\n",
       "      <td>Age</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>MEX</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>13.60</td>\n",
       "      <td>22.049999</td>\n",
       "      <td>5.45</td>\n",
       "      <td>2.5024</td>\n",
       "      <td>3.8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2223jMWDEGNeszivb</td>\n",
       "      <td>-1683127088_785070916172117.0</td>\n",
       "      <td>785070916172117.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>CHE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.90</td>\n",
       "      <td>4.200000</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.5076</td>\n",
       "      <td>0.6237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>222HpiEf2LtAwEg62</td>\n",
       "      <td>-1232628507_1597557389</td>\n",
       "      <td>1597557389.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Female</td>\n",
       "      <td>Gender</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UKR</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.65</td>\n",
       "      <td>13.25</td>\n",
       "      <td>21.750000</td>\n",
       "      <td>5.95</td>\n",
       "      <td>7.4120</td>\n",
       "      <td>5.6984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222KuWty7pNeiv77a</td>\n",
       "      <td>1654911454_3639764894860440.0</td>\n",
       "      <td>3639764894860440.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Low</td>\n",
       "      <td>Social Status</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>USA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>12.50</td>\n",
       "      <td>17.850000</td>\n",
       "      <td>7.25</td>\n",
       "      <td>3.9603</td>\n",
       "      <td>1.9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222LDp4wz24C3chzj</td>\n",
       "      <td>-1679158262_3623236506.0</td>\n",
       "      <td>3623236506.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>DEU</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4.20</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>2.15</td>\n",
       "      <td>1.9120</td>\n",
       "      <td>0.6120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ResponseID              ExtendedSessionID              UserID  \\\n",
       "0  2223Xu54ufgjcyMR3   1425316635_327833569077076.0   327833569077076.0   \n",
       "1  2223jMWDEGNeszivb  -1683127088_785070916172117.0   785070916172117.0   \n",
       "2  222HpiEf2LtAwEg62         -1232628507_1597557389        1597557389.0   \n",
       "3  222KuWty7pNeiv77a  1654911454_3639764894860440.0  3639764894860440.0   \n",
       "4  222LDp4wz24C3chzj       -1679158262_3623236506.0        3623236506.0   \n",
       "\n",
       "   PedPed  Barrier  CrossingSignal AttributeLevel ScenarioTypeStrict  \\\n",
       "0       0        1               0            Old                Age   \n",
       "1       1        0               2           More        Utilitarian   \n",
       "2       0        1               0         Female             Gender   \n",
       "3       1        0               0            Low      Social Status   \n",
       "4       0        0               0            Fat            Fitness   \n",
       "\n",
       "   NumberOfCharacters  DiffNumberOFCharacters  Saved Country  Man  Woman  \\\n",
       "0                   5                       0      0     MEX    0      0   \n",
       "1                   5                       2      0     CHE    0      0   \n",
       "2                   2                       0      0     UKR    0      0   \n",
       "3                   2                       0      0     USA    0      0   \n",
       "4                   2                       0      0     DEU    1      0   \n",
       "\n",
       "   Pregnant  Stroller  OldMan  OldWoman  Boy  Girl  Homeless  LargeWoman  \\\n",
       "0         0         0       2         3    0     0         0           0   \n",
       "1         0         0       1         0    0     0         0           0   \n",
       "2         0         0       0         1    0     0         0           1   \n",
       "3         0         0       0         0    0     0         2           0   \n",
       "4         0         0       0         0    0     0         0           1   \n",
       "\n",
       "   LargeMan  Criminal  MaleExecutive  FemaleExecutive  FemaleAthlete  \\\n",
       "0         0         0              0                0              0   \n",
       "1         0         1              1                0              1   \n",
       "2         0         0              0                0              0   \n",
       "3         0         0              0                0              0   \n",
       "4         0         0              0                0              0   \n",
       "\n",
       "   MaleAthlete  FemaleDoctor  MaleDoctor  Dog  Cat  Finance_access   ICT  \\\n",
       "0            0             0           0    0    0            0.60  0.55   \n",
       "1            0             0           0    1    0            0.90  0.65   \n",
       "2            0             0           0    0    0            0.75  0.50   \n",
       "3            0             0           0    0    0            0.90  0.65   \n",
       "4            0             0           0    0    0            0.80  0.80   \n",
       "\n",
       "   Industry_activity  Overall_index  Research_and_development  Skills  Total  \\\n",
       "0               0.80           0.60                       0.5    0.40  13.60   \n",
       "1               0.90           0.90                       0.7    0.80   2.90   \n",
       "2               0.65           0.65                       0.5    0.65  13.25   \n",
       "3               0.80           1.00                       1.0    0.75  12.50   \n",
       "4               0.90           0.90                       0.8    0.75   4.20   \n",
       "\n",
       "       Males  Females  Passengers  Pedestrians  \n",
       "0  22.049999     5.45      2.5024       3.8760  \n",
       "1   4.200000     1.60      0.5076       0.6237  \n",
       "2  21.750000     5.95      7.4120       5.6984  \n",
       "3  17.850000     7.25      3.9603       1.9737  \n",
       "4   6.350000     2.15      1.9120       0.6120  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the columns 'ResponseID', ExtendedSessionID' and 'UserID' and 'Country'\n",
    "df = df.drop(['ResponseID', 'ExtendedSessionID', 'UserID', 'Country'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['NumberOfCharacters', 'DiffNumberOFCharacters', 'Man', 'Woman', 'Pregnant', 'Stroller', 'OldMan', 'OldWoman', 'Boy', 'Girl', 'Homeless', 'LargeWoman', 'LargeMan', 'Criminal', 'MaleExecutive', 'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete', 'FemaleDoctor', 'MaleDoctor', 'Dog', 'Cat', 'Finance_access', 'ICT', 'Industry_activity', 'Overall_index', 'Research_and_development', 'Skills', 'Total', 'Males', 'Females', 'Passengers', 'Pedestrians']\n",
    "cat_cols = ['AttributeLevel', 'ScenarioTypeStrict', 'CrossingSignal'] #Categorical columns that shouldn't be scaled: 'CrossingSignal'\n",
    "binary_cols = ['PedPed', 'Barrier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the numerical columns\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encode the categorical columns\n",
    "labelencoder = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = labelencoder.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>NumberOfCharacters</th>\n",
       "      <th>DiffNumberOFCharacters</th>\n",
       "      <th>Saved</th>\n",
       "      <th>Man</th>\n",
       "      <th>Woman</th>\n",
       "      <th>Pregnant</th>\n",
       "      <th>Stroller</th>\n",
       "      <th>OldMan</th>\n",
       "      <th>OldWoman</th>\n",
       "      <th>Boy</th>\n",
       "      <th>Girl</th>\n",
       "      <th>Homeless</th>\n",
       "      <th>LargeWoman</th>\n",
       "      <th>LargeMan</th>\n",
       "      <th>Criminal</th>\n",
       "      <th>MaleExecutive</th>\n",
       "      <th>FemaleExecutive</th>\n",
       "      <th>FemaleAthlete</th>\n",
       "      <th>MaleAthlete</th>\n",
       "      <th>FemaleDoctor</th>\n",
       "      <th>MaleDoctor</th>\n",
       "      <th>Dog</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Finance_access</th>\n",
       "      <th>ICT</th>\n",
       "      <th>Industry_activity</th>\n",
       "      <th>Overall_index</th>\n",
       "      <th>Research_and_development</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Total</th>\n",
       "      <th>Males</th>\n",
       "      <th>Females</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Pedestrians</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1.355313</td>\n",
       "      <td>-0.483363</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.525093</td>\n",
       "      <td>-0.525323</td>\n",
       "      <td>-0.233628</td>\n",
       "      <td>-0.227924</td>\n",
       "      <td>3.519691</td>\n",
       "      <td>5.458979</td>\n",
       "      <td>-0.349847</td>\n",
       "      <td>-0.350054</td>\n",
       "      <td>-0.276851</td>\n",
       "      <td>-0.350099</td>\n",
       "      <td>-0.350039</td>\n",
       "      <td>-0.227544</td>\n",
       "      <td>-0.304694</td>\n",
       "      <td>-0.305035</td>\n",
       "      <td>-0.358794</td>\n",
       "      <td>-0.35871</td>\n",
       "      <td>-0.28825</td>\n",
       "      <td>-0.288368</td>\n",
       "      <td>-0.299649</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>-2.087185</td>\n",
       "      <td>-0.997931</td>\n",
       "      <td>0.062204</td>\n",
       "      <td>-1.920313</td>\n",
       "      <td>-1.103975</td>\n",
       "      <td>-2.651884</td>\n",
       "      <td>0.895208</td>\n",
       "      <td>1.028475</td>\n",
       "      <td>0.377931</td>\n",
       "      <td>-0.485556</td>\n",
       "      <td>2.023675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1.355313</td>\n",
       "      <td>1.287652</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.525093</td>\n",
       "      <td>-0.525323</td>\n",
       "      <td>-0.233628</td>\n",
       "      <td>-0.227924</td>\n",
       "      <td>1.580369</td>\n",
       "      <td>-0.359223</td>\n",
       "      <td>-0.349847</td>\n",
       "      <td>-0.350054</td>\n",
       "      <td>-0.276851</td>\n",
       "      <td>-0.350099</td>\n",
       "      <td>-0.350039</td>\n",
       "      <td>3.776382</td>\n",
       "      <td>2.591354</td>\n",
       "      <td>-0.305035</td>\n",
       "      <td>1.581299</td>\n",
       "      <td>-0.35871</td>\n",
       "      <td>-0.28825</td>\n",
       "      <td>-0.288368</td>\n",
       "      <td>1.496821</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>0.806543</td>\n",
       "      <td>-0.199999</td>\n",
       "      <td>1.252444</td>\n",
       "      <td>0.266284</td>\n",
       "      <td>-0.170225</td>\n",
       "      <td>0.597756</td>\n",
       "      <td>-1.208276</td>\n",
       "      <td>-1.166040</td>\n",
       "      <td>-1.246748</td>\n",
       "      <td>-1.752301</td>\n",
       "      <td>-0.941406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.667810</td>\n",
       "      <td>-0.483363</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.525093</td>\n",
       "      <td>-0.525323</td>\n",
       "      <td>-0.233628</td>\n",
       "      <td>-0.227924</td>\n",
       "      <td>-0.358953</td>\n",
       "      <td>1.580178</td>\n",
       "      <td>-0.349847</td>\n",
       "      <td>-0.350054</td>\n",
       "      <td>-0.276851</td>\n",
       "      <td>1.920806</td>\n",
       "      <td>-0.350039</td>\n",
       "      <td>-0.227544</td>\n",
       "      <td>-0.304694</td>\n",
       "      <td>-0.305035</td>\n",
       "      <td>-0.358794</td>\n",
       "      <td>-0.35871</td>\n",
       "      <td>-0.28825</td>\n",
       "      <td>-0.288368</td>\n",
       "      <td>-0.299649</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>-0.640321</td>\n",
       "      <td>-1.396898</td>\n",
       "      <td>-1.723157</td>\n",
       "      <td>-1.555881</td>\n",
       "      <td>-1.103975</td>\n",
       "      <td>-0.620859</td>\n",
       "      <td>0.826402</td>\n",
       "      <td>0.991592</td>\n",
       "      <td>0.588928</td>\n",
       "      <td>2.632155</td>\n",
       "      <td>3.685135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.667810</td>\n",
       "      <td>-0.483363</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.525093</td>\n",
       "      <td>-0.525323</td>\n",
       "      <td>-0.233628</td>\n",
       "      <td>-0.227924</td>\n",
       "      <td>-0.358953</td>\n",
       "      <td>-0.359223</td>\n",
       "      <td>-0.349847</td>\n",
       "      <td>-0.350054</td>\n",
       "      <td>4.994596</td>\n",
       "      <td>-0.350099</td>\n",
       "      <td>-0.350039</td>\n",
       "      <td>-0.227544</td>\n",
       "      <td>-0.304694</td>\n",
       "      <td>-0.305035</td>\n",
       "      <td>-0.358794</td>\n",
       "      <td>-0.35871</td>\n",
       "      <td>-0.28825</td>\n",
       "      <td>-0.288368</td>\n",
       "      <td>-0.299649</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>0.806543</td>\n",
       "      <td>-0.199999</td>\n",
       "      <td>0.062204</td>\n",
       "      <td>0.995150</td>\n",
       "      <td>1.230399</td>\n",
       "      <td>0.191551</td>\n",
       "      <td>0.678962</td>\n",
       "      <td>0.512118</td>\n",
       "      <td>1.137521</td>\n",
       "      <td>0.440244</td>\n",
       "      <td>0.289372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.667810</td>\n",
       "      <td>-0.483363</td>\n",
       "      <td>0</td>\n",
       "      <td>1.167251</td>\n",
       "      <td>-0.525323</td>\n",
       "      <td>-0.233628</td>\n",
       "      <td>-0.227924</td>\n",
       "      <td>-0.358953</td>\n",
       "      <td>-0.359223</td>\n",
       "      <td>-0.349847</td>\n",
       "      <td>-0.350054</td>\n",
       "      <td>-0.276851</td>\n",
       "      <td>1.920806</td>\n",
       "      <td>-0.350039</td>\n",
       "      <td>-0.227544</td>\n",
       "      <td>-0.304694</td>\n",
       "      <td>-0.305035</td>\n",
       "      <td>-0.358794</td>\n",
       "      <td>-0.35871</td>\n",
       "      <td>-0.28825</td>\n",
       "      <td>-0.288368</td>\n",
       "      <td>-0.299649</td>\n",
       "      <td>-0.29939</td>\n",
       "      <td>-0.158033</td>\n",
       "      <td>0.996900</td>\n",
       "      <td>1.252444</td>\n",
       "      <td>0.266284</td>\n",
       "      <td>0.296650</td>\n",
       "      <td>0.191551</td>\n",
       "      <td>-0.952712</td>\n",
       "      <td>-0.901715</td>\n",
       "      <td>-1.014651</td>\n",
       "      <td>-0.860474</td>\n",
       "      <td>-0.952073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PedPed  Barrier  CrossingSignal  AttributeLevel  ScenarioTypeStrict  \\\n",
       "0       0        1               0               9                   0   \n",
       "1       1        0               2               8                   6   \n",
       "2       0        1               0               1                   2   \n",
       "3       1        0               0               6                   4   \n",
       "4       0        0               0               0                   1   \n",
       "\n",
       "   NumberOfCharacters  DiffNumberOFCharacters  Saved       Man     Woman  \\\n",
       "0            1.355313               -0.483363      0 -0.525093 -0.525323   \n",
       "1            1.355313                1.287652      0 -0.525093 -0.525323   \n",
       "2           -0.667810               -0.483363      0 -0.525093 -0.525323   \n",
       "3           -0.667810               -0.483363      0 -0.525093 -0.525323   \n",
       "4           -0.667810               -0.483363      0  1.167251 -0.525323   \n",
       "\n",
       "   Pregnant  Stroller    OldMan  OldWoman       Boy      Girl  Homeless  \\\n",
       "0 -0.233628 -0.227924  3.519691  5.458979 -0.349847 -0.350054 -0.276851   \n",
       "1 -0.233628 -0.227924  1.580369 -0.359223 -0.349847 -0.350054 -0.276851   \n",
       "2 -0.233628 -0.227924 -0.358953  1.580178 -0.349847 -0.350054 -0.276851   \n",
       "3 -0.233628 -0.227924 -0.358953 -0.359223 -0.349847 -0.350054  4.994596   \n",
       "4 -0.233628 -0.227924 -0.358953 -0.359223 -0.349847 -0.350054 -0.276851   \n",
       "\n",
       "   LargeWoman  LargeMan  Criminal  MaleExecutive  FemaleExecutive  \\\n",
       "0   -0.350099 -0.350039 -0.227544      -0.304694        -0.305035   \n",
       "1   -0.350099 -0.350039  3.776382       2.591354        -0.305035   \n",
       "2    1.920806 -0.350039 -0.227544      -0.304694        -0.305035   \n",
       "3   -0.350099 -0.350039 -0.227544      -0.304694        -0.305035   \n",
       "4    1.920806 -0.350039 -0.227544      -0.304694        -0.305035   \n",
       "\n",
       "   FemaleAthlete  MaleAthlete  FemaleDoctor  MaleDoctor       Dog      Cat  \\\n",
       "0      -0.358794     -0.35871      -0.28825   -0.288368 -0.299649 -0.29939   \n",
       "1       1.581299     -0.35871      -0.28825   -0.288368  1.496821 -0.29939   \n",
       "2      -0.358794     -0.35871      -0.28825   -0.288368 -0.299649 -0.29939   \n",
       "3      -0.358794     -0.35871      -0.28825   -0.288368 -0.299649 -0.29939   \n",
       "4      -0.358794     -0.35871      -0.28825   -0.288368 -0.299649 -0.29939   \n",
       "\n",
       "   Finance_access       ICT  Industry_activity  Overall_index  \\\n",
       "0       -2.087185 -0.997931           0.062204      -1.920313   \n",
       "1        0.806543 -0.199999           1.252444       0.266284   \n",
       "2       -0.640321 -1.396898          -1.723157      -1.555881   \n",
       "3        0.806543 -0.199999           0.062204       0.995150   \n",
       "4       -0.158033  0.996900           1.252444       0.266284   \n",
       "\n",
       "   Research_and_development    Skills     Total     Males   Females  \\\n",
       "0                 -1.103975 -2.651884  0.895208  1.028475  0.377931   \n",
       "1                 -0.170225  0.597756 -1.208276 -1.166040 -1.246748   \n",
       "2                 -1.103975 -0.620859  0.826402  0.991592  0.588928   \n",
       "3                  1.230399  0.191551  0.678962  0.512118  1.137521   \n",
       "4                  0.296650  0.191551 -0.952712 -0.901715 -1.014651   \n",
       "\n",
       "   Passengers  Pedestrians  \n",
       "0   -0.485556     2.023675  \n",
       "1   -1.752301    -0.941406  \n",
       "2    2.632155     3.685135  \n",
       "3    0.440244     0.289372  \n",
       "4   -0.860474    -0.952073  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading completed successfully.\n",
      "Number of training samples: 8499993\n",
      "Number of test samples: 1499999\n"
     ]
    }
   ],
   "source": [
    "# Assume cleaned_data is already loaded as a pandas DataFrame\n",
    "# Example: cleaned_data = pd.read_csv('your_large_dataset.csv')\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 100_000\n",
    "\n",
    "# Split features (X) and labels (y)\n",
    "X = df.drop(columns=['Saved'])  # Assuming 'target' is the label column\n",
    "y = df['Saved']\n",
    "\n",
    "# Optionally, you can split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "# Define a generator for batching the data\n",
    "def data_generator(X, y, batch_size):\n",
    "    num_samples = len(X)\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "        # Shuffle data at the start of each epoch\n",
    "        indices = np.arange(num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        X = X.iloc[indices]\n",
    "        y = y.iloc[indices]\n",
    "        \n",
    "        # Yield batches\n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "            yield X.iloc[start_idx:end_idx].values, y.iloc[start_idx:end_idx].values\n",
    "\n",
    "# Load data in batches using the generator\n",
    "train_data_gen = data_generator(X_train, y_train, batch_size)\n",
    "test_data_gen = data_generator(X_test, y_test, batch_size)\n",
    "\n",
    "# Print information about the dataset and generator\n",
    "try:\n",
    "    # Get number of samples in train and test sets\n",
    "    num_train_samples = len(X_train)\n",
    "    num_test_samples = len(X_test)\n",
    "    \n",
    "    print(\"Data loading completed successfully.\")\n",
    "    print(f\"Number of training samples: {num_train_samples}\")\n",
    "    print(f\"Number of test samples: {num_test_samples}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timoklein/Library/CloudStorage/OneDrive-Personal/Universiteit/Studie/M_Data_Science_and_Society/year_2/Thesis/Code/timoklein/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(32, activation='relu', kernel_initializer=initializers.HeNormal(), input_shape=(df.shape[1] - 1,)))\n",
    "    model.add(layers.Dense(16, activation='relu', kernel_initializer=initializers.HeNormal()))\n",
    "    model.add(layers.Dense(1, activation='sigmoid', kernel_initializer=initializers.HeNormal()))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1/5...\n",
      "Epoch 1/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 174ms/step - accuracy: 0.5385 - loss: 0.7413 - val_accuracy: 0.6071 - val_loss: 0.6533\n",
      "Epoch 2/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.6137 - loss: 0.6510 - val_accuracy: 0.6407 - val_loss: 0.6349\n",
      "Epoch 3/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 152ms/step - accuracy: 0.6406 - loss: 0.6356 - val_accuracy: 0.6546 - val_loss: 0.6252\n",
      "Epoch 4/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.6534 - loss: 0.6266 - val_accuracy: 0.6633 - val_loss: 0.6189\n",
      "Epoch 5/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 0.6613 - loss: 0.6198 - val_accuracy: 0.6688 - val_loss: 0.6145\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step\n",
      "Fold 1 accuracy: 0.5021460537610809\n",
      "Training fold 2/5...\n",
      "Epoch 1/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 216ms/step - accuracy: 0.6679 - loss: 0.6136 - val_accuracy: 0.6726 - val_loss: 0.6084\n",
      "Epoch 2/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 124ms/step - accuracy: 0.6696 - loss: 0.6112 - val_accuracy: 0.6777 - val_loss: 0.6042\n",
      "Epoch 3/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 116ms/step - accuracy: 0.6735 - loss: 0.6074 - val_accuracy: 0.6810 - val_loss: 0.6014\n",
      "Epoch 4/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 106ms/step - accuracy: 0.6767 - loss: 0.6042 - val_accuracy: 0.6830 - val_loss: 0.5997\n",
      "Epoch 5/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 122ms/step - accuracy: 0.6792 - loss: 0.6016 - val_accuracy: 0.6846 - val_loss: 0.5981\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step\n",
      "Fold 2 accuracy: 0.5031636842105263\n",
      "Training fold 3/5...\n",
      "Epoch 1/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 166ms/step - accuracy: 0.6822 - loss: 0.5984 - val_accuracy: 0.6839 - val_loss: 0.5950\n",
      "Epoch 2/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.6817 - loss: 0.5980 - val_accuracy: 0.6858 - val_loss: 0.5930\n",
      "Epoch 3/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 117ms/step - accuracy: 0.6834 - loss: 0.5959 - val_accuracy: 0.6875 - val_loss: 0.5915\n",
      "Epoch 4/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 112ms/step - accuracy: 0.6851 - loss: 0.5940 - val_accuracy: 0.6890 - val_loss: 0.5906\n",
      "Epoch 5/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 121ms/step - accuracy: 0.6868 - loss: 0.5923 - val_accuracy: 0.6903 - val_loss: 0.5900\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step\n",
      "Fold 3 accuracy: 0.5019342125623291\n",
      "Training fold 4/5...\n",
      "Epoch 1/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 210ms/step - accuracy: 0.6893 - loss: 0.5898 - val_accuracy: 0.6908 - val_loss: 0.5863\n",
      "Epoch 2/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - accuracy: 0.6887 - loss: 0.5896 - val_accuracy: 0.6938 - val_loss: 0.5839\n",
      "Epoch 3/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 137ms/step - accuracy: 0.6908 - loss: 0.5874 - val_accuracy: 0.6963 - val_loss: 0.5821\n",
      "Epoch 4/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 123ms/step - accuracy: 0.6932 - loss: 0.5852 - val_accuracy: 0.6980 - val_loss: 0.5811\n",
      "Epoch 5/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 107ms/step - accuracy: 0.6954 - loss: 0.5834 - val_accuracy: 0.6985 - val_loss: 0.5804\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 62ms/step\n",
      "Fold 4 accuracy: 0.5016963157894737\n",
      "Training fold 5/5...\n",
      "Epoch 1/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 193ms/step - accuracy: 0.6993 - loss: 0.5804 - val_accuracy: 0.7021 - val_loss: 0.5775\n",
      "Epoch 2/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 129ms/step - accuracy: 0.6994 - loss: 0.5806 - val_accuracy: 0.7047 - val_loss: 0.5757\n",
      "Epoch 3/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 131ms/step - accuracy: 0.7014 - loss: 0.5791 - val_accuracy: 0.7058 - val_loss: 0.5748\n",
      "Epoch 4/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 133ms/step - accuracy: 0.7032 - loss: 0.5777 - val_accuracy: 0.7056 - val_loss: 0.5748\n",
      "Epoch 5/5\n",
      "\u001b[1m79/79\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 118ms/step - accuracy: 0.7047 - loss: 0.5767 - val_accuracy: 0.7057 - val_loss: 0.5749\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step\n",
      "Fold 5 accuracy: 0.5022847392470939\n",
      "Average accuracy across 5 folds: 0.5022450011141008\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "k_folds = 5\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 100_000\n",
    "\n",
    "# Assume cleaned_data is already loaded as a pandas DataFrame\n",
    "# Example: cleaned_data = pd.read_csv('your_large_dataset.csv')\n",
    "\n",
    "# Split features (X) and labels (y)\n",
    "X = df.drop(columns=['Saved'])  # Assuming 'target' is the label column\n",
    "y = df['Saved']\n",
    "\n",
    "# Define a generator for batching the data\n",
    "def data_generator(X, y, batch_size):\n",
    "    num_samples = len(X)\n",
    "    while True:  # Loop forever so the generator never terminates\n",
    "        # Yield batches\n",
    "        for start_idx in range(0, num_samples, batch_size):\n",
    "            end_idx = min(start_idx + batch_size, num_samples)\n",
    "            yield X.iloc[start_idx:end_idx].values, y.iloc[start_idx:end_idx].values\n",
    "\n",
    "# Initialize KFold from scikit-learn\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Array to store accuracy for each fold\n",
    "fold_accuracies = []\n",
    "\n",
    "# Loop through each fold\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X)):\n",
    "    print(f\"Training fold {fold+1}/{k_folds}...\")\n",
    "\n",
    "    # Create train and validation sets for this fold\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # Create generators for this fold\n",
    "    train_data_gen = data_generator(X_train, y_train, batch_size)\n",
    "    val_data_gen = data_generator(X_val, y_val, batch_size)\n",
    "\n",
    "    # Define your model here\n",
    "    # For simplicity, let's assume we have a Keras model defined as 'model'\n",
    "    # You would need to reinitialize your model for each fold (since the model should be retrained from scratch)\n",
    "    # model = create_model()  # Assuming this function creates a fresh instance of your model\n",
    "\n",
    "    # Train the model on this fold\n",
    "    model.fit(\n",
    "        train_data_gen,\n",
    "        steps_per_epoch=len(X_train) // batch_size,\n",
    "        validation_data=val_data_gen,\n",
    "        validation_steps=len(X_val) // batch_size,\n",
    "        epochs=5  # You can adjust the number of epochs as needed\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the validation set (using the generator)\n",
    "    val_predictions = model.predict(val_data_gen, steps=len(X_val) // batch_size)\n",
    "    \n",
    "    # Assuming your target values are categorical, you might need to convert predictions to class labels\n",
    "    val_predictions = np.argmax(val_predictions, axis=1)  # Convert probabilities to class labels\n",
    "    \n",
    "    # Calculate accuracy for this fold\n",
    "    accuracy = accuracy_score(y_val[:len(val_predictions)], val_predictions)\n",
    "    fold_accuracies.append(accuracy)\n",
    "\n",
    "    print(f\"Fold {fold+1} accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"Average accuracy across {k_folds} folds: {average_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timoklein/Library/CloudStorage/OneDrive-Personal/Universiteit/Studie/M_Data_Science_and_Society/year_2/Thesis/Code/timoklein/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(32, activation='relu', kernel_initializer=initializers.HeNormal(), input_shape=(X_train.shape[1],)))\n",
    "    model.add(layers.Dense(16, activation='relu', kernel_initializer=initializers.HeNormal()))\n",
    "    model.add(layers.Dense(1, activation='sigmoid', kernel_initializer=initializers.HeNormal()))\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 207ms/step - accuracy: 0.5672 - loss: 0.6850 - val_accuracy: 0.6438 - val_loss: 0.6332\n",
      "Epoch 2/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 273ms/step - accuracy: 0.6491 - loss: 0.6284 - val_accuracy: 0.6661 - val_loss: 0.6170\n",
      "Epoch 3/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 362ms/step - accuracy: 0.6682 - loss: 0.6151 - val_accuracy: 0.6749 - val_loss: 0.6078\n",
      "Epoch 4/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 297ms/step - accuracy: 0.6781 - loss: 0.6058 - val_accuracy: 0.6826 - val_loss: 0.6000\n",
      "Epoch 5/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 366ms/step - accuracy: 0.6846 - loss: 0.5989 - val_accuracy: 0.6881 - val_loss: 0.5936\n",
      "Epoch 6/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 361ms/step - accuracy: 0.6903 - loss: 0.5928 - val_accuracy: 0.6945 - val_loss: 0.5877\n",
      "Epoch 7/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 351ms/step - accuracy: 0.6971 - loss: 0.5856 - val_accuracy: 0.7019 - val_loss: 0.5819\n",
      "Epoch 8/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 311ms/step - accuracy: 0.7040 - loss: 0.5806 - val_accuracy: 0.7063 - val_loss: 0.5781\n",
      "Epoch 9/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 359ms/step - accuracy: 0.7081 - loss: 0.5768 - val_accuracy: 0.7097 - val_loss: 0.5743\n",
      "Epoch 10/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 293ms/step - accuracy: 0.7100 - loss: 0.5745 - val_accuracy: 0.7106 - val_loss: 0.5725\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1376bf860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume you have a Keras model called `model`\n",
    "model.fit(\n",
    "    train_data_gen,  # Training data generator\n",
    "    steps_per_epoch=len(X_train) // batch_size,  # Total steps per epoch\n",
    "    validation_data=val_data_gen,  # Test data generator\n",
    "    validation_steps=len(X_val) // batch_size,  # Validation steps per epoch\n",
    "    epochs=10  # Number of epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set (using the generator)\n",
    "val_predictions = model.predict(val_data_gen, steps=len(X_val) // batch_size)\n",
    "    \n",
    "# Assuming your target values are categorical, you might need to convert predictions to class labels\n",
    "val_predictions = np.argmax(val_predictions, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Calculate accuracy for this fold\n",
    "accuracy = accuracy_score(y_val[:len(val_predictions)], val_predictions)\n",
    "fold_accuracies.append(accuracy)\n",
    "print(f\"Fold {fold+1} accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "average_accuracy = np.mean(fold_accuracies)\n",
    "print(f\"Average accuracy across {k_folds} folds: {average_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
