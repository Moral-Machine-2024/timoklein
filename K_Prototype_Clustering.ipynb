{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Prototype Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target encoding and include LICENSE in timoklein?? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for K-Protoptype Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1\n",
      "Finished processing chunk 1\n",
      "Processing chunk 2\n",
      "Finished processing chunk 2\n",
      "Processing chunk 3\n",
      "Finished processing chunk 3\n",
      "Processing chunk 4\n",
      "Finished processing chunk 4\n",
      "Processing chunk 5\n",
      "Finished processing chunk 5\n",
      "Processing chunk 6\n",
      "Finished processing chunk 6\n",
      "Processing chunk 7\n",
      "Finished processing chunk 7\n",
      "Processing chunk 8\n",
      "Finished processing chunk 8\n",
      "Processing chunk 9\n",
      "Finished processing chunk 9\n",
      "Processing chunk 10\n",
      "Finished processing chunk 10\n",
      "Processing chunk 11\n",
      "Finished processing chunk 11\n",
      "Processing chunk 12\n",
      "Finished processing chunk 12\n",
      "Processing chunk 13\n",
      "Finished processing chunk 13\n",
      "Processing chunk 14\n",
      "Finished processing chunk 14\n",
      "Processing chunk 15\n",
      "Finished processing chunk 15\n",
      "Processing chunk 16\n",
      "Finished processing chunk 16\n",
      "Processing chunk 17\n",
      "Finished processing chunk 17\n",
      "Processing chunk 18\n",
      "Finished processing chunk 18\n",
      "Processing chunk 19\n",
      "Finished processing chunk 19\n",
      "Processing chunk 20\n",
      "Finished processing chunk 20\n",
      "Processing chunk 21\n",
      "Finished processing chunk 21\n",
      "Processing chunk 22\n",
      "Finished processing chunk 22\n",
      "Processing chunk 23\n",
      "Finished processing chunk 23\n",
      "Processing chunk 24\n",
      "Finished processing chunk 24\n",
      "Processing chunk 25\n",
      "Finished processing chunk 25\n",
      "Processing chunk 26\n",
      "Finished processing chunk 26\n",
      "Processing chunk 27\n",
      "Finished processing chunk 27\n",
      "Processing chunk 28\n",
      "Finished processing chunk 28\n",
      "Processing chunk 29\n",
      "Finished processing chunk 29\n",
      "Processing chunk 30\n",
      "Finished processing chunk 30\n",
      "Processing chunk 31\n",
      "Finished processing chunk 31\n",
      "Processing chunk 32\n",
      "Finished processing chunk 32\n",
      "Processing chunk 33\n",
      "Finished processing chunk 33\n",
      "Processing chunk 34\n",
      "Finished processing chunk 34\n",
      "Processing chunk 35\n",
      "Finished processing chunk 35\n",
      "Processing chunk 36\n",
      "Finished processing chunk 36\n",
      "Processing chunk 37\n",
      "Finished processing chunk 37\n",
      "Processing chunk 38\n",
      "Finished processing chunk 38\n",
      "Processing chunk 39\n",
      "Finished processing chunk 39\n",
      "Processing chunk 40\n",
      "Finished processing chunk 40\n",
      "Processing chunk 41\n",
      "Finished processing chunk 41\n",
      "Processing chunk 42\n",
      "Finished processing chunk 42\n",
      "Processing chunk 43\n",
      "Finished processing chunk 43\n",
      "Processing chunk 44\n",
      "Finished processing chunk 44\n",
      "Processing chunk 45\n",
      "Finished processing chunk 45\n",
      "Processing chunk 46\n",
      "Finished processing chunk 46\n",
      "Processing chunk 47\n",
      "Finished processing chunk 47\n",
      "Processing chunk 48\n",
      "Finished processing chunk 48\n",
      "Processing chunk 49\n",
      "Finished processing chunk 49\n",
      "Processing chunk 50\n",
      "Finished processing chunk 50\n",
      "Processing chunk 51\n",
      "Finished processing chunk 51\n",
      "Processing chunk 52\n",
      "Finished processing chunk 52\n",
      "Processing chunk 53\n",
      "Finished processing chunk 53\n",
      "Processing chunk 54\n",
      "Finished processing chunk 54\n",
      "Processing chunk 55\n",
      "Finished processing chunk 55\n",
      "Processing chunk 56\n",
      "Finished processing chunk 56\n",
      "Processing chunk 57\n",
      "Finished processing chunk 57\n",
      "Processing chunk 58\n",
      "Finished processing chunk 58\n",
      "Processing chunk 59\n",
      "Finished processing chunk 59\n",
      "Processing chunk 60\n",
      "Finished processing chunk 60\n",
      "Processing chunk 61\n",
      "Finished processing chunk 61\n",
      "Processing chunk 62\n",
      "Finished processing chunk 62\n",
      "Processing chunk 63\n",
      "Finished processing chunk 63\n",
      "Processing chunk 64\n",
      "Finished processing chunk 64\n",
      "Processing chunk 65\n",
      "Finished processing chunk 65\n",
      "Processing chunk 66\n",
      "Finished processing chunk 66\n",
      "Processing chunk 67\n",
      "Finished processing chunk 67\n",
      "Processing chunk 68\n",
      "Finished processing chunk 68\n",
      "Processing chunk 69\n",
      "Finished processing chunk 69\n",
      "Processing chunk 70\n",
      "Finished processing chunk 70\n",
      "Processing chunk 71\n",
      "Finished processing chunk 71\n",
      "Processing chunk 72\n",
      "Finished processing chunk 72\n",
      "Processing chunk 73\n",
      "Finished processing chunk 73\n",
      "Processing chunk 74\n",
      "Finished processing chunk 74\n",
      "Processing chunk 75\n",
      "Finished processing chunk 75\n",
      "Processing chunk 76\n",
      "Finished processing chunk 76\n",
      "Processing chunk 77\n",
      "Finished processing chunk 77\n",
      "Processing chunk 78\n",
      "Finished processing chunk 78\n",
      "Processing chunk 79\n",
      "Finished processing chunk 79\n",
      "Processing chunk 80\n",
      "Finished processing chunk 80\n",
      "Processing chunk 81\n",
      "Finished processing chunk 81\n",
      "Processing chunk 82\n",
      "Finished processing chunk 82\n",
      "Processing chunk 83\n",
      "Finished processing chunk 83\n",
      "Processing chunk 84\n",
      "Finished processing chunk 84\n",
      "Processing chunk 85\n",
      "Finished processing chunk 85\n",
      "Processing chunk 86\n",
      "Finished processing chunk 86\n",
      "Processing chunk 87\n",
      "Finished processing chunk 87\n",
      "Processing chunk 88\n",
      "Finished processing chunk 88\n",
      "Processing chunk 89\n",
      "Finished processing chunk 89\n",
      "Processing chunk 90\n",
      "Finished processing chunk 90\n",
      "Processing chunk 91\n",
      "Finished processing chunk 91\n",
      "Processing chunk 92\n",
      "Finished processing chunk 92\n",
      "Processing chunk 93\n",
      "Finished processing chunk 93\n",
      "Processing chunk 94\n",
      "Finished processing chunk 94\n",
      "Processing chunk 95\n",
      "Finished processing chunk 95\n",
      "Processing chunk 96\n",
      "Finished processing chunk 96\n",
      "Processing chunk 97\n",
      "Finished processing chunk 97\n",
      "Processing chunk 98\n",
      "Finished processing chunk 98\n",
      "Processing chunk 99\n",
      "Finished processing chunk 99\n",
      "Processing chunk 100\n",
      "Finished processing chunk 100\n",
      "All chunks have been processed\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/cleaned_data.csv', chunksize=100_000, dtype=str, low_memory=False)\n",
    "\n",
    "chunks = []\n",
    "for i, chunk in enumerate(df):\n",
    "    print(f\"Processing chunk {i+1}\")\n",
    "\n",
    "    chunks.append(chunk)\n",
    "    \n",
    "    print(f\"Finished processing chunk {i+1}\")\n",
    "print(\"All chunks have been processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kpc = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the 'Saved' column\n",
    "df_kpc.drop(columns=['Saved'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical columns\n",
    "num_cols = ['Finance_access', 'ICT', 'Industry_activity', 'Overall_index', 'Research_and_development', 'Skills', 'Total', 'Males', 'Females', 'Passengers', 'Pedestrians']\n",
    "cat_cols = ['ResponseID', 'ExtendedSessionID', 'UserID', 'PedPed', 'Barrier', 'CrossingSignal', 'AttributeLevel', 'ScenarioTypeStrict', 'NumberOfCharacters', 'DiffNumberOFCharacters', 'Man', 'Woman', 'Pregnant', 'Stroller', 'OldMan', 'OldWoman', 'Boy', 'Girl', 'Homeless', 'LargeWoman', 'LargeMan', 'Criminal', 'MaleExecutive', 'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete', 'FemaleDoctor', 'MaleDoctor', 'Dog', 'Cat']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the numerical columns\n",
    "scaler = StandardScaler()\n",
    "df_kpc[num_cols] = scaler.fit_transform(df_kpc[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ResponseID</th>\n",
       "      <th>ExtendedSessionID</th>\n",
       "      <th>UserID</th>\n",
       "      <th>PedPed</th>\n",
       "      <th>Barrier</th>\n",
       "      <th>CrossingSignal</th>\n",
       "      <th>AttributeLevel</th>\n",
       "      <th>ScenarioTypeStrict</th>\n",
       "      <th>NumberOfCharacters</th>\n",
       "      <th>DiffNumberOFCharacters</th>\n",
       "      <th>...</th>\n",
       "      <th>ICT</th>\n",
       "      <th>Industry_activity</th>\n",
       "      <th>Overall_index</th>\n",
       "      <th>Research_and_development</th>\n",
       "      <th>Skills</th>\n",
       "      <th>Total</th>\n",
       "      <th>Males</th>\n",
       "      <th>Females</th>\n",
       "      <th>Passengers</th>\n",
       "      <th>Pedestrians</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2223Xu54ufgjcyMR3</td>\n",
       "      <td>1425316635_327833569077076.0</td>\n",
       "      <td>327833569077076</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Old</td>\n",
       "      <td>Age</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.998571</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>-1.922477</td>\n",
       "      <td>-1.105562</td>\n",
       "      <td>-2.656801</td>\n",
       "      <td>0.895903</td>\n",
       "      <td>1.029890</td>\n",
       "      <td>0.376946</td>\n",
       "      <td>-0.486371</td>\n",
       "      <td>2.022779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2223jMWDEGNeszivb</td>\n",
       "      <td>-1683127088_785070916172117.0</td>\n",
       "      <td>785070916172117</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199389</td>\n",
       "      <td>1.253962</td>\n",
       "      <td>0.264436</td>\n",
       "      <td>-0.172077</td>\n",
       "      <td>0.595988</td>\n",
       "      <td>-1.210274</td>\n",
       "      <td>-1.168000</td>\n",
       "      <td>-1.248525</td>\n",
       "      <td>-1.754420</td>\n",
       "      <td>-0.939921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2224YxTZcu4sJqTSD</td>\n",
       "      <td>-887960483_174929057557052.0</td>\n",
       "      <td>174929057557052</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Hoomans</td>\n",
       "      <td>Species</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>0.264436</td>\n",
       "      <td>-0.172077</td>\n",
       "      <td>0.189389</td>\n",
       "      <td>-0.639441</td>\n",
       "      <td>-0.681632</td>\n",
       "      <td>-0.467454</td>\n",
       "      <td>0.293604</td>\n",
       "      <td>-0.704985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2225gNWJcAeE92LXd</td>\n",
       "      <td>2069688900_9887644874714294.0</td>\n",
       "      <td>9887644874714300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>More</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999383</td>\n",
       "      <td>1.253962</td>\n",
       "      <td>0.264436</td>\n",
       "      <td>0.294666</td>\n",
       "      <td>0.189389</td>\n",
       "      <td>-0.954383</td>\n",
       "      <td>-0.903269</td>\n",
       "      <td>-1.016314</td>\n",
       "      <td>-0.861675</td>\n",
       "      <td>-0.950579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2229A3nHWnXQBFMf5</td>\n",
       "      <td>-835212059_2515956109.0</td>\n",
       "      <td>2515956109</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Fat</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.598980</td>\n",
       "      <td>0.063409</td>\n",
       "      <td>-0.464535</td>\n",
       "      <td>-0.172077</td>\n",
       "      <td>-0.623808</td>\n",
       "      <td>-0.659125</td>\n",
       "      <td>-0.558501</td>\n",
       "      <td>-0.889654</td>\n",
       "      <td>-0.580706</td>\n",
       "      <td>-0.626279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ResponseID              ExtendedSessionID            UserID PedPed  \\\n",
       "0  2223Xu54ufgjcyMR3   1425316635_327833569077076.0   327833569077076      0   \n",
       "1  2223jMWDEGNeszivb  -1683127088_785070916172117.0   785070916172117      1   \n",
       "2  2224YxTZcu4sJqTSD   -887960483_174929057557052.0   174929057557052      0   \n",
       "3  2225gNWJcAeE92LXd  2069688900_9887644874714294.0  9887644874714300      0   \n",
       "4  2229A3nHWnXQBFMf5        -835212059_2515956109.0        2515956109      0   \n",
       "\n",
       "  Barrier CrossingSignal AttributeLevel ScenarioTypeStrict NumberOfCharacters  \\\n",
       "0       1              0            Old                Age                  5   \n",
       "1       0              2           More        Utilitarian                  5   \n",
       "2       0              2        Hoomans            Species                  5   \n",
       "3       1              0           More        Utilitarian                  5   \n",
       "4       1              0            Fat            Fitness                  1   \n",
       "\n",
       "  DiffNumberOFCharacters  ...       ICT Industry_activity Overall_index  \\\n",
       "0                      0  ... -0.998571          0.063409     -1.922477   \n",
       "1                      2  ... -0.199389          1.253962      0.264436   \n",
       "2                      0  ...  0.999383          0.063409      0.264436   \n",
       "3                      4  ...  0.999383          1.253962      0.264436   \n",
       "4                      0  ... -0.598980          0.063409     -0.464535   \n",
       "\n",
       "  Research_and_development    Skills     Total     Males   Females Passengers  \\\n",
       "0                -1.105562 -2.656801  0.895903  1.029890  0.376946  -0.486371   \n",
       "1                -0.172077  0.595988 -1.210274 -1.168000 -1.248525  -1.754420   \n",
       "2                -0.172077  0.189389 -0.639441 -0.681632 -0.467454   0.293604   \n",
       "3                 0.294666  0.189389 -0.954383 -0.903269 -1.016314  -0.861675   \n",
       "4                -0.172077 -0.623808 -0.659125 -0.558501 -0.889654  -0.580706   \n",
       "\n",
       "  Pedestrians  \n",
       "0    2.022779  \n",
       "1   -0.939921  \n",
       "2   -0.704985  \n",
       "3   -0.950579  \n",
       "4   -0.626279  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kpc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to NumPy array\n",
    "np_kpc = df_kpc.to_numpy()\n",
    "\n",
    "# Specify the indices of categorical columns\n",
    "cat_col_indices = [df_kpc.columns.get_loc(col) for col in cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the k-Prototypes model\n",
    "kproto = KPrototypes(n_clusters= 5, init='Cao', random_state=42)\n",
    "\n",
    "# Fit the model to your data\n",
    "clusters = kproto.fit_predict(np_kpc, categorical=cat_col_indices)\n",
    "\n",
    "# Add the cluster labels to your DataFrame\n",
    "df['Cluster'] = clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
